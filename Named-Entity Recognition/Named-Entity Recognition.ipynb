{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "[nltk_data] Downloading package punkt to /home/wenbo/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Model, Input\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>have</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>marched</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>through</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>London</td>\n",
       "      <td>B-geo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>to</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>protest</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>the</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word    Tag\n",
       "0  Sentence: 1      Thousands      O\n",
       "1  Sentence: 1             of      O\n",
       "2  Sentence: 1  demonstrators      O\n",
       "3  Sentence: 1           have      O\n",
       "4  Sentence: 1        marched      O\n",
       "5  Sentence: 1        through      O\n",
       "6  Sentence: 1         London  B-geo\n",
       "7  Sentence: 1             to      O\n",
       "8  Sentence: 1        protest      O\n",
       "9  Sentence: 1            the      O"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"ner_dataset.csv\", encoding=\"latin1\")\n",
    "data = data.drop(['POS'], axis =1)\n",
    "data = data.fillna(method=\"ffill\")\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Sentence #               Word    Tag\n",
      "264    Sentence: 12  Non-Proliferation  I-art\n",
      "3811  Sentence: 171                V-6  I-art\n",
      "4016  Sentence: 183             Simple  I-art\n",
      "4017  Sentence: 183               Life  I-art\n",
      "4142  Sentence: 188            Morning  I-art\n",
      "4143  Sentence: 188            America  I-art\n",
      "5248  Sentence: 236             Mirror  I-art\n",
      "5923  Sentence: 270                 De  I-art\n",
      "5924  Sentence: 270             Gaulle  I-art\n",
      "5935  Sentence: 270      International  I-art\n"
     ]
    }
   ],
   "source": [
    "print(data.loc[data['Tag'] == 'I-art'][0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceGetter(object):\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, t) for w, t in zip(s[\"Word\"].values.tolist(),s[\"Tag\"].values.tolist())]\n",
    "        self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "    \n",
    "    def get_next(self):\n",
    "        try:\n",
    "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
    "            self.n_sent += 1\n",
    "            return s\n",
    "        except:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "getter = SentenceGetter(data)\n",
    "sentences = getter.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Thousands', 'O'), ('of', 'O'), ('demonstrators', 'O'), ('have', 'O'), ('marched', 'O'), ('through', 'O'), ('London', 'B-geo'), ('to', 'O'), ('protest', 'O'), ('the', 'O'), ('war', 'O'), ('in', 'O'), ('Iraq', 'B-geo'), ('and', 'O'), ('demand', 'O'), ('the', 'O'), ('withdrawal', 'O'), ('of', 'O'), ('British', 'B-gpe'), ('troops', 'O'), ('from', 'O'), ('that', 'O'), ('country', 'O'), ('.', 'O')]\n"
     ]
    }
   ],
   "source": [
    "print(sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_text(text):\n",
    "    sentence = []\n",
    "    for word in text.split():\n",
    "        if word.startswith(\"*\"):\n",
    "            sentence.append((word[1:], \"B-geo\"))\n",
    "        elif word.startswith(\"!\"):\n",
    "            sentence.append((word[1:], \"I-art\"))\n",
    "        else:\n",
    "            sentence.append((word, \"O\"))\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = \"I lived in *Munich last summer. *Germany has a relaxing, slow summer lifestyle. One night, I got food poisoning and couldn't find !Tylenol to make the pain go away, they insisted I take !aspirin instead.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I', 'O'), ('lived', 'O'), ('in', 'O'), ('Munich', 'B-geo'), ('last', 'O'), ('summer.', 'O'), ('Germany', 'B-geo'), ('has', 'O'), ('a', 'O'), ('relaxing,', 'O'), ('slow', 'O'), ('summer', 'O'), ('lifestyle.', 'O'), ('One', 'O'), ('night,', 'O'), ('I', 'O'), ('got', 'O'), ('food', 'O'), ('poisoning', 'O'), ('and', 'O'), (\"couldn't\", 'O'), ('find', 'O'), ('Tylenol', 'I-art'), ('to', 'O'), ('make', 'O'), ('the', 'O'), ('pain', 'O'), ('go', 'O'), ('away,', 'O'), ('they', 'O'), ('insisted', 'O'), ('I', 'O'), ('take', 'O'), ('aspirin', 'I-art'), ('instead.', 'O')]\n"
     ]
    }
   ],
   "source": [
    "sentence = tag_text(train_text)\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(set(data[\"Word\"].values))\n",
    "words.append(\"ENDPAD\")\n",
    "for word in sentence:\n",
    "    if word[0] not in words:\n",
    "        words.append(word[0])\n",
    "n_words = len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = list(set(data[\"Tag\"].values))\n",
    "n_tags = len(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx = {w: i for i, w in enumerate(words)}\n",
    "tag2idx = {t: i for i, t in enumerate(tags)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 50\n",
    "\n",
    "X = [[word2idx[w[0]] for w in s] for s in sentences]\n",
    "X = pad_sequences(maxlen=max_len, sequences=X, padding=\"post\",value=word2idx[\"ENDPAD\"])\n",
    "\n",
    "y = [[tag2idx[w[1]] for w in s] for s in sentences]\n",
    "y = pad_sequences(maxlen=max_len, sequences=y, padding=\"post\", value=tag2idx[\"O\"])\n",
    "\n",
    "y = [to_categorical(i, num_classes=n_tags) for i in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_te, y_tr, y_te = train_test_split(X[0:-2], y[0:-2], test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38366\n",
      "38366\n"
     ]
    }
   ],
   "source": [
    "print(len(X_tr))\n",
    "print(len(y_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Augment training data with user's input data\n",
    "X_tr = np.vstack((X_tr, X[-1]))\n",
    "y_tr.append(y[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38367\n",
      "38367\n"
     ]
    }
   ],
   "source": [
    "print(len(X_tr))\n",
    "print(len(y_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Input(shape=(max_len,))\n",
    "model = Embedding(input_dim=n_words, output_dim=max_len, input_length=max_len)(input)\n",
    "model = Dropout(0.1)(model)\n",
    "model = Bidirectional(LSTM(units=100, return_sequences=True, recurrent_dropout=0.1))(model)\n",
    "out = TimeDistributed(Dense(n_tags, activation=\"softmax\"))(model)\n",
    "\n",
    "model = Model(input, out)\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30693 samples, validate on 7674 samples\n",
      "Epoch 1/3\n",
      "30693/30693 [==============================] - 151s 5ms/step - loss: 0.2129 - acc: 0.9529 - val_loss: 0.0811 - val_acc: 0.9772\n",
      "Epoch 2/3\n",
      "30693/30693 [==============================] - 148s 5ms/step - loss: 0.0583 - acc: 0.9830 - val_loss: 0.0563 - val_acc: 0.9836\n",
      "Epoch 3/3\n",
      "30693/30693 [==============================] - 151s 5ms/step - loss: 0.0404 - acc: 0.9878 - val_loss: 0.0519 - val_acc: 0.9847\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "history = model.fit(X_tr,\\\n",
    "                    np.array(y_tr),\\\n",
    "                    batch_size = 32,\\\n",
    "                    epochs = 3,\\\n",
    "                    validation_split = 0.2,\\\n",
    "                    verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 50, 50)            1759400   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50, 50)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 50, 200)           120800    \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 50, 17)            3417      \n",
      "=================================================================\n",
      "Total params: 1,883,617\n",
      "Trainable params: 1,883,617\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9592/9592 [==============================] - 16s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Test model\n",
    "test_pred = model.predict(np.array(X_te), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wenbo/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-art       0.00      0.00      0.00        81\n",
      "       B-eve       1.00      0.03      0.06        67\n",
      "       B-geo       0.88      0.85      0.86      7466\n",
      "       B-gpe       0.95      0.93      0.94      3177\n",
      "       B-nat       0.00      0.00      0.00        35\n",
      "       B-org       0.75      0.69      0.72      4013\n",
      "       B-per       0.82      0.81      0.81      3419\n",
      "       B-tim       0.91      0.87      0.89      4053\n",
      "       I-art       0.00      0.00      0.00        48\n",
      "       I-eve       0.00      0.00      0.00        61\n",
      "       I-geo       0.81      0.76      0.78      1454\n",
      "       I-gpe       1.00      0.23      0.37        31\n",
      "       I-nat       0.00      0.00      0.00         8\n",
      "       I-org       0.76      0.77      0.77      3452\n",
      "       I-per       0.85      0.85      0.85      3539\n",
      "       I-tim       0.82      0.70      0.75      1248\n",
      "           O       0.99      1.00      1.00    447448\n",
      "\n",
      "   micro avg       0.98      0.98      0.98    479600\n",
      "   macro avg       0.62      0.50      0.52    479600\n",
      "weighted avg       0.98      0.98      0.98    479600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idx2tag = {i: w for w, i in tag2idx.items()}\n",
    "\n",
    "def pred2label(pred):\n",
    "    out = []\n",
    "    for pred_i in pred:\n",
    "        for p in pred_i:\n",
    "            p_i = np.argmax(p, axis = -1)\n",
    "            out.append(idx2tag[p_i])\n",
    "    return out\n",
    "\n",
    "pred_labels = pred2label(test_pred)\n",
    "true_labels = pred2label(y_te)\n",
    "\n",
    "print(classification_report(true_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test user's text\n",
    "test_text = \"When I lived in Paris last year, France was experiencing a recession. The night life was too fun, I developed an addiction to Adderall and Ritalin.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_tokens = word_tokenize(test_text)\n",
    "X_test = []\n",
    "for token in list_tokens:\n",
    "    if token not in word2idx:\n",
    "        word2idx[token] = len(word2idx)\n",
    "        words.append(token)\n",
    "    X_test.append(word2idx[token])\n",
    "\n",
    "X_test = pad_sequences(maxlen=max_len, sequences=[X_test], padding=\"post\",value=word2idx[\"ENDPAD\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word           (Pred)\n",
      "When          : O\n",
      "I             : O\n",
      "lived         : O\n",
      "in            : O\n",
      "Paris         : B-geo\n",
      "last          : O\n",
      "year          : O\n",
      ",             : O\n",
      "France        : B-geo\n",
      "was           : O\n",
      "experiencing  : O\n",
      "a             : O\n",
      "recession     : O\n",
      ".             : O\n",
      "The           : O\n",
      "night         : O\n",
      "life          : O\n",
      "was           : O\n",
      "too           : O\n",
      "fun           : O\n",
      ",             : O\n",
      "I             : O\n",
      "developed     : O\n",
      "an            : O\n",
      "addiction     : O\n",
      "to            : O\n",
      "Adderall      : O\n",
      "and           : O\n",
      "Ritalin       : O\n",
      ".             : O\n",
      "ENDPAD        : O\n",
      "ENDPAD        : O\n",
      "ENDPAD        : O\n",
      "ENDPAD        : O\n",
      "ENDPAD        : O\n",
      "ENDPAD        : O\n",
      "ENDPAD        : O\n",
      "ENDPAD        : O\n",
      "ENDPAD        : O\n",
      "ENDPAD        : O\n",
      "ENDPAD        : O\n",
      "ENDPAD        : O\n",
      "ENDPAD        : O\n",
      "ENDPAD        : O\n",
      "ENDPAD        : O\n",
      "ENDPAD        : O\n",
      "ENDPAD        : O\n",
      "ENDPAD        : O\n",
      "ENDPAD        : O\n",
      "ENDPAD        : O\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "p = model.predict(np.array(X_test))\n",
    "p = np.argmax(p, axis=-1)\n",
    "print(\"{:14} ({:4})\".format(\"Word\", \"Pred\"))\n",
    "for w,pred in zip(X_test[i],p[0]):\n",
    "    print(\"{:14}: {}\".format(words[w],tags[pred]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
